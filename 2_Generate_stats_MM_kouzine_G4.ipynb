{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-22 10:18:50.411262: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-22 10:18:50.598367: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-22 10:18:51.905472: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-22 10:18:51.905623: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-04-22 10:18:51.905639: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import os\n",
    "from joblib import dump, load\n",
    "from sparse_vector.sparse_vector import SparseVector\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from transformers import BertModel, BertConfig, PreTrainedTokenizer, BasicTokenizer, BertForTokenClassification\n",
    "import collections\n",
    "from transformers import utils\n",
    "from torch.utils.data import DataLoader\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import defaultdict\n",
    "from dna_tokenizer import DNATokenizer, seq2kmer\n",
    "import logging\n",
    "logging.disable(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PredDataset(data.Dataset):\n",
    "    def __init__(self, chroms, dna_source, intervals, tokenizer):\n",
    "\n",
    "        self.chroms = chroms\n",
    "        self.intervals = intervals\n",
    "        self.tokenizer = tokenizer\n",
    "        self.dna_source = dna_source\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.intervals)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        interval = self.intervals[index]\n",
    "        chrom = interval[0]\n",
    "        begin = interval[1]\n",
    "        end = interval[2]\n",
    "\n",
    "        k_mers = seq2kmer(self.dna_source[chrom][begin:end+5].upper(),6)\n",
    "        encoded_k_mers = self.tokenizer.encode_plus(k_mers, add_special_tokens=False, max_length=512)[\"input_ids\"]\n",
    "\n",
    "        return torch.LongTensor(encoded_k_mers), (chrom, begin, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 128\n",
    "pad = 192\n",
    "k_mer_pad = 5\n",
    "\n",
    "def final_prediction(chrom, DNA, models, device):\n",
    "    \n",
    "    intervals = []\n",
    "    ends = []\n",
    "    \n",
    "    \n",
    "    prediction = np.zeros(len(DNA[chrom]), dtype=np.float32)\n",
    "    \n",
    "    \n",
    "    for st in range(0, len(DNA[chrom]) - 512, width):\n",
    "        interval = [st, min(st + 512, len(DNA[chrom]))]\n",
    "        intervals.append([chrom, interval[0], interval[1]])\n",
    "        \n",
    "    pred_dataset = PredDataset(chroms, DNA, intervals, \n",
    "                               DNATokenizer.from_pretrained('6-new-12w-0/', add_special_tokens=False))\n",
    "\n",
    "    params = {'batch_size':32, 'num_workers':5, 'shuffle':False}\n",
    "    load_predict = data.DataLoader(pred_dataset, **params)\n",
    "\n",
    "    \n",
    "    for model_i, model in enumerate(models):\n",
    "    \n",
    "        model.to(device)\n",
    "        with torch.no_grad():\n",
    "            for input_ids, intervals in tqdm(load_predict):\n",
    "                input_ids = input_ids.to(device)\n",
    "                outputs = torch.softmax(model(input_ids = input_ids)['logits'],axis = -1).cpu().numpy()[:,:,1]\n",
    "                for ind, interval in enumerate(zip(intervals[0], intervals[1], intervals[2])): \n",
    "                    if interval[1] == 0:\n",
    "                        prediction[interval[1]:interval[2]] = outputs[ind]\n",
    "                    else:    \n",
    "                        prediction[interval[1]+pad:interval[2]] = outputs[ind, pad:]\n",
    "                    \n",
    "        dump(prediction, f'/gim/lv01/dumerenkov/MM9_G4/MM9_kouzine_{model_i}_{chrom}', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                           | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|███████▊                                                                                                                                                           | 1/21 [00:00<00:05,  3.79it/s]\u001b[A\n",
      " 10%|███████████████▌                                                                                                                                                   | 2/21 [00:00<00:04,  3.87it/s]\u001b[A\n",
      " 14%|███████████████████████▎                                                                                                                                           | 3/21 [00:00<00:04,  4.17it/s]\u001b[A\n",
      " 19%|███████████████████████████████                                                                                                                                    | 4/21 [00:00<00:04,  4.22it/s]\u001b[A\n",
      " 24%|██████████████████████████████████████▊                                                                                                                            | 5/21 [00:01<00:03,  4.22it/s]\u001b[A\n",
      " 29%|██████████████████████████████████████████████▌                                                                                                                    | 6/21 [00:01<00:03,  4.27it/s]\u001b[A\n",
      " 33%|██████████████████████████████████████████████████████▎                                                                                                            | 7/21 [00:01<00:03,  4.31it/s]\u001b[A\n",
      " 38%|██████████████████████████████████████████████████████████████                                                                                                     | 8/21 [00:01<00:02,  4.53it/s]\u001b[A\n",
      " 43%|█████████████████████████████████████████████████████████████████████▊                                                                                             | 9/21 [00:02<00:02,  4.74it/s]\u001b[A\n",
      " 48%|█████████████████████████████████████████████████████████████████████████████▏                                                                                    | 10/21 [00:02<00:02,  4.83it/s]\u001b[A\n",
      " 52%|████████████████████████████████████████████████████████████████████████████████████▊                                                                             | 11/21 [00:02<00:01,  5.08it/s]\u001b[A\n",
      " 57%|████████████████████████████████████████████████████████████████████████████████████████████▌                                                                     | 12/21 [00:02<00:01,  5.31it/s]\u001b[A\n",
      " 62%|████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                             | 13/21 [00:02<00:01,  5.38it/s]\u001b[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                      | 14/21 [00:02<00:01,  5.41it/s]\u001b[A\n",
      " 71%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                              | 15/21 [00:03<00:01,  5.69it/s]\u001b[A\n",
      " 76%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                      | 16/21 [00:03<00:00,  6.00it/s]\u001b[A\n",
      " 81%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                              | 17/21 [00:03<00:00,  6.29it/s]\u001b[A\n",
      " 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 18/21 [00:03<00:00,  6.55it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.26it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "chroms = [f'chr{i}' for i in list(range(1, 20)) + ['X', 'Y']]\n",
    "DNA = {chrom:load(f'../data/mm9_dna/sparse/{chrom}.pkl') for chrom in tqdm(chroms)}\n",
    "\n",
    "G4_kouzine = {}\n",
    "for chrom in DNA:\n",
    "    G4_kouzine[chrom] = np.zeros(len(DNA[chrom]), dtype = bool)\n",
    "    \n",
    "    \n",
    "with open(\"actB_ssDNA_enriched_Quadruplex.bed\")as f:\n",
    "    for idx, line in enumerate(f):\n",
    "        if idx>0:\n",
    "            chrom, start, end, _ , _ , _ = line.strip().split()\n",
    "            if chrom in G4_kouzine:\n",
    "                G4_kouzine[chrom][int(start):int(end)] = 1\n",
    "                \n",
    "G4 = G4_kouzine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "for MODEL_NUMBER in range(5):\n",
    "    dir_to_pretrained_model = f'dnabert_mm_fold_{MODEL_NUMBER}_kouzine_g4'\n",
    "    model = BertForTokenClassification.from_pretrained(dir_to_pretrained_model)\n",
    "    model.eval()\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN CHROM chr1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48144/48144 [4:00:16<00:00,  3.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48144/48144 [3:59:48<00:00,  3.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48144/48144 [3:59:43<00:00,  3.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48144/48144 [3:59:32<00:00,  3.35it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 48144/48144 [3:59:31<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGIN CHROM chr2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44372/44372 [3:40:51<00:00,  3.35it/s]\n",
      " 12%|█████████████████▉                                                                                                                                         | 5146/44372 [25:34<3:15:09,  3.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 48%|████████████████████████████████████████████████████████████████████████▌                                                                               | 21174/44372 [1:45:19<1:55:22,  3.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 85%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                       | 37509/44372 [3:06:35<34:05,  3.36it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 22%|█████████████████████████████████▉                                                                                                                         | 9713/44372 [48:19<2:52:38,  3.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 59%|██████████████████████████████████████████████████████████████████████████████████████████                                                              | 26307/44372 [2:10:55<1:29:53,  3.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 42318/44372 [3:30:36<10:15,  3.34it/s]IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 17%|██████████████████████████                                                                                                                                 | 7469/44372 [37:08<3:03:40,  3.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 31%|██████████████████████████████████████████████▉                                                                                                         | 13692/44372 [1:08:06<2:32:39,  3.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 53%|████████████████████████████████████████████████████████████████████████████████▍                                                                       | 23499/44372 [1:56:53<1:43:39,  3.36it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 67%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                  | 29720/44372 [2:27:50<1:12:52,  3.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 89%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                | 39593/44372 [3:16:56<23:46,  3.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "  3%|████                                                                                                                                                       | 1158/44372 [05:44<3:35:17,  3.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 25%|██████████████████████████████████████▏                                                                                                                   | 10986/44372 [54:37<2:46:03,  3.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 39%|██████████████████████████████████████████████████████████▌                                                                                             | 17097/44372 [1:25:02<2:15:41,  3.35it/s]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 56%|████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 24808/44372 [2:03:24<1:37:19,  3.35it/s]"
     ]
    }
   ],
   "source": [
    "for chrom in chroms:\n",
    "    print(f\"BEGIN CHROM {chrom}\")\n",
    "    final_prediction(chrom, DNA, models, device = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized, divisions = load('mm_divisions_kouzine_g4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [05:33<00:00, 15.89s/it]\n"
     ]
    }
   ],
   "source": [
    "com_len = sum([len(DNA[chrom]) for chrom in chroms])\n",
    "sums = []\n",
    "\n",
    "for chrom in tqdm(chroms):\n",
    "    loc_sum = []\n",
    "    for model_num in range(5):\n",
    "        vec = load(f'/gim/lv01/dumerenkov/MM9_G4/MM9_kouzine_{model_num}_{chrom}')\n",
    "        loc_sum.append(vec.sum())\n",
    "    sums.append(loc_sum)\n",
    "\n",
    "multipliers = np.array(sums).sum(axis=0) / com_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [20:28<00:00, 58.50s/it]\n"
     ]
    }
   ],
   "source": [
    "for chrom in tqdm(chroms):\n",
    "    vecs = np.array([load(f'/gim/lv01/dumerenkov/MM9_G4/MM9_kouzine_{model_num}_{chrom}') \n",
    "                     for model_num in range(5)])\n",
    "    res_vec = (vecs / multipliers[:, None]) * multipliers.mean()\n",
    "    mean_vec = res_vec.mean(axis=0)\n",
    "    \n",
    "    test_ints = []\n",
    "    for MODEL_NUMBER in range(5):\n",
    "        train_inds, test_inds = divisions[MODEL_NUMBER]\n",
    "        train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]\n",
    "        test_ints.extend([(MODEL_NUMBER, inter) for inter in test_intervals if inter[0] == chrom])\n",
    "    \n",
    "    for model_num, inters in test_ints:\n",
    "        mean_vec[inters[1]: inters[2]] = res_vec[model_num, inters[1]: inters[2]]\n",
    "    dump(mean_vec, f'/gim/lv01/dumerenkov/MM9_G4/MM9_kouzine_res_{chrom}', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [03:11<00:00,  9.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988107344940106\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9971    0.9985 2654251788\n",
      "           1     0.0682    0.8727    0.1265    643430\n",
      "\n",
      "    accuracy                         0.9971 2654895218\n",
      "   macro avg     0.5341    0.9349    0.5625 2654895218\n",
      "weighted avg     0.9997    0.9971    0.9983 2654895218\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_pred = []\n",
    "all_true = []\n",
    "for chrom in tqdm(chroms):\n",
    "    true_clean = G4[chrom][:].astype(int)\n",
    "    all_pred.append(load(f'/gim/lv01/dumerenkov/MM9_G4/MM9_kouzine_res_{chrom}'))\n",
    "    all_true.append(true_clean)\n",
    "    \n",
    "print(roc_auc_score(np.concatenate(all_true), np.concatenate(all_pred)))\n",
    "print(sklearn.metrics.classification_report(np.concatenate(all_true), np.concatenate(all_pred)>0.5, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "def to_fwf(df, fname):\n",
    "    content = tabulate(df.values.tolist(), tablefmt=\"plain\")\n",
    "    open(fname, \"w\").write(content)\n",
    "\n",
    "pd.DataFrame.to_fwf = to_fwf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                           | 0/21 [00:00<?, ?it/s]\u001b[A\n",
      "  5%|███████▍                                                                                                                                                    | 1/21 [2:33:20<51:06:56, 9200.83s/it]\u001b[A\n",
      " 10%|██████████████▊                                                                                                                                             | 2/21 [5:25:41<52:05:51, 9871.14s/it]\u001b[A\n",
      " 14%|██████████████████████▎                                                                                                                                     | 3/21 [6:58:16<39:30:09, 7900.54s/it]\u001b[A\n",
      " 19%|█████████████████████████████▋                                                                                                                              | 4/21 [8:45:04<34:31:31, 7311.27s/it]\u001b[A\n",
      " 24%|████████████████████████████████████▉                                                                                                                      | 5/21 [10:28:46<30:44:57, 6918.57s/it]\u001b[A\n",
      " 29%|████████████████████████████████████████████▎                                                                                                              | 6/21 [11:56:11<26:27:23, 6349.57s/it]\u001b[A\n",
      " 33%|███████████████████████████████████████████████████▋                                                                                                       | 7/21 [13:33:29<24:02:32, 6182.32s/it]\u001b[A\n",
      " 38%|███████████████████████████████████████████████████████████                                                                                                | 8/21 [14:43:42<20:03:38, 5555.24s/it]\u001b[A\n",
      " 43%|██████████████████████████████████████████████████████████████████▍                                                                                        | 9/21 [15:41:13<16:19:29, 4897.46s/it]\u001b[A\n",
      " 48%|█████████████████████████████████████████████████████████████████████████▎                                                                                | 10/21 [16:47:56<14:07:15, 4621.37s/it]\u001b[A\n",
      " 52%|████████████████████████████████████████████████████████████████████████████████▋                                                                         | 11/21 [17:53:08<12:14:02, 4404.25s/it]\u001b[A\n",
      " 57%|████████████████████████████████████████████████████████████████████████████████████████                                                                  | 12/21 [18:48:05<10:10:05, 4067.30s/it]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████████████████████████████████████████████████▉                                                           | 13/21 [19:38:46<8:20:50, 3756.30s/it]\u001b[A\n",
      " 67%|███████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                   | 14/21 [20:35:26<7:05:41, 3648.72s/it]\u001b[A\n",
      " 71%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                            | 15/21 [21:20:22<5:36:10, 3361.72s/it]\u001b[A\n",
      " 76%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 16/21 [21:54:36<4:07:20, 2968.12s/it]\u001b[A\n",
      " 81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                             | 17/21 [22:32:49<3:04:20, 2765.07s/it]\u001b[A\n",
      " 86%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                      | 18/21 [23:02:00<2:03:00, 2460.15s/it]\u001b[A\n",
      " 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏              | 19/21 [23:16:26<1:06:02, 1981.43s/it]\u001b[A\n",
      " 95%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌       | 20/21 [25:03:41<55:18, 3318.62s/it]\u001b[A\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21/21 [25:03:49<00:00, 4296.63s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "pchroms, starts, ends = [], [], []\n",
    "model_confidence_threshold = 0.25\n",
    "min_length = 6\n",
    "\n",
    "chroms = [f'chr{i}' for i in list(range(1, 20)) + ['X', 'Y']]\n",
    "\n",
    "for chrom in tqdm(chroms):\n",
    "    pred = load(f'/gim/lv01/dumerenkov/MM9_G4/MM9_kouzine_res_{chrom}')\n",
    "    labeled, max_label = scipy.ndimage.label(pred>model_confidence_threshold)\n",
    "    for idx in range(1,max_label+1):\n",
    "        where = np.where(labeled == idx)[0]\n",
    "        start = where[0]\n",
    "        end = where[-1] + 1\n",
    "        \n",
    "        if end-start>min_length:\n",
    "            pchroms.append(chrom)\n",
    "            starts.append(start)\n",
    "            ends.append(end)\n",
    "pd.DataFrame(list(zip(pchroms, starts, ends))).to_fwf(f'beds/MM9_thr_{model_confidence_threshold}_minlen_{min_length}.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
